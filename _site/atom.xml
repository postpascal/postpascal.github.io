<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.3">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-05-08T18:36:49+08:00</updated><id>http://localhost:4000/</id><title type="html">无何有之乡 广袤之野</title><subtitle>stay hungry stay foolish</subtitle><author><name>Zhang Keke</name><email>apostpascal@gmail.com</email></author><entry><title type="html">Connect server with spawn and expect</title><link href="http://localhost:4000/tools/ssh-connect/" rel="alternate" type="text/html" title="Connect server with spawn and expect" /><published>2018-05-08T00:00:00+08:00</published><updated>2018-05-08T00:00:00+08:00</updated><id>http://localhost:4000/tools/ssh-connect</id><content type="html" xml:base="http://localhost:4000/tools/ssh-connect/">&lt;p&gt;&lt;a href=&quot;https://www.thegeekstuff.com/2010/10/expect-examples&quot;&gt;expect spawn and send&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/usr/bin/expect -f&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#set timeout 20&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;sp YourSudoPassword
&lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;passwd UserPassword

&lt;span class=&quot;c&quot;&gt;# sudo is not always necessary&lt;/span&gt;

spawn &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;ssh user@ip

expect &lt;span class=&quot;s2&quot;&gt;&quot;Password:&quot;&lt;/span&gt;
send &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$sp&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\r&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

expect &lt;span class=&quot;s2&quot;&gt;&quot;some stuff&quot;&lt;/span&gt;
send &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$passwd&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\r&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
interact
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;spawn: run commands&lt;/li&gt;
  &lt;li&gt;expect: wait for specify pattern&lt;/li&gt;
  &lt;li&gt;send: to send the strings to the process&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Zhang Keke</name></author><category term="ssh" /><category term="spawn" /><category term="server" /><summary type="html">expect spawn and send</summary></entry><entry><title type="html">Use jupyter on remote server</title><link href="http://localhost:4000/tools/remote-jupyter/" rel="alternate" type="text/html" title="Use jupyter on remote server" /><published>2018-05-08T00:00:00+08:00</published><updated>2018-05-08T00:00:00+08:00</updated><id>http://localhost:4000/tools/remote-jupyter</id><content type="html" xml:base="http://localhost:4000/tools/remote-jupyter/">&lt;p&gt;If you want to use jupyter on remote server, this blog might be useful.&lt;/p&gt;

&lt;p&gt;Step1:
Run jupyter without browser on  remote server:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook &lt;span class=&quot;nt&quot;&gt;--no-browser&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;8888
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Step2:
Bind local port to remote server:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh &lt;span class=&quot;nt&quot;&gt;-N&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-L&lt;/span&gt; localhost:8888:ip:8888 user@ip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Step3:
Open browser on you local machine and direct to &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:8888&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To Stop Local Process:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ps aux|grep jupyter

&lt;span class=&quot;nb&quot;&gt;kill &lt;/span&gt;pid
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Zhang Keke</name></author><category term="jupyter" /><summary type="html">If you want to use jupyter on remote server, this blog might be useful.</summary></entry><entry><title type="html">Layout: Post with Table Of Contents</title><link href="http://localhost:4000/layout/tt/" rel="alternate" type="text/html" title="Layout: Post with Table Of Contents" /><published>2018-04-25T00:00:00+08:00</published><updated>2018-04-25T00:00:00+08:00</updated><id>http://localhost:4000/layout/tt</id><content type="html" xml:base="http://localhost:4000/layout/tt/">&lt;p&gt;Enable table of contents on post or page by adding &lt;code class=&quot;highlighter-rouge&quot;&gt;{% include toc %}&lt;/code&gt; where you’d like it to appear.&lt;/p&gt;

&lt;div id=&quot;entry-table-of-contents&quot; class=&quot;toc-wrapper&quot;&gt;
  &lt;h2 id=&quot;toc-toggle&quot; class=&quot;no_toc&quot;&gt;
  Table of Contents &lt;i class=&quot;toc-toggle-icon fas fa-chevron-down&quot;&gt;&lt;/i&gt;
&lt;/h2&gt;
&lt;ol id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#html-elements&quot; id=&quot;markdown-toc-html-elements&quot;&gt;HTML Elements&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#body-text&quot; id=&quot;markdown-toc-body-text&quot;&gt;Body text&lt;/a&gt;    &lt;ol&gt;
      &lt;li&gt;&lt;a href=&quot;#blockquotes&quot; id=&quot;markdown-toc-blockquotes&quot;&gt;Blockquotes&lt;/a&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#list-types&quot; id=&quot;markdown-toc-list-types&quot;&gt;List Types&lt;/a&gt;    &lt;ol&gt;
      &lt;li&gt;&lt;a href=&quot;#ordered-lists&quot; id=&quot;markdown-toc-ordered-lists&quot;&gt;Ordered Lists&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#unordered-lists&quot; id=&quot;markdown-toc-unordered-lists&quot;&gt;Unordered Lists&lt;/a&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#tables&quot; id=&quot;markdown-toc-tables&quot;&gt;Tables&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#code-snippets&quot; id=&quot;markdown-toc-code-snippets&quot;&gt;Code Snippets&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#buttons&quot; id=&quot;markdown-toc-buttons&quot;&gt;Buttons&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#notices&quot; id=&quot;markdown-toc-notices&quot;&gt;Notices&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;

&lt;h2 id=&quot;html-elements&quot;&gt;HTML Elements&lt;/h2&gt;

&lt;p&gt;Below is are some HTML elements. Check the source code to see the many embedded elements within paragraphs.&lt;/p&gt;

&lt;h2 id=&quot;body-text&quot;&gt;Body text&lt;/h2&gt;

&lt;p&gt;Lorem ipsum dolor sit amet, test link adipiscing elit. &lt;strong&gt;This is strong&lt;/strong&gt;. Nullam dignissim convallis est. Quisque aliquam.&lt;/p&gt;

&lt;p class=&quot;image-right&quot;&gt;&lt;img src=&quot;/images/3953273590_704e3899d5_m.jpg&quot; alt=&quot;Smithsonian Image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is emphasized&lt;/em&gt;. Donec faucibus. Nunc iaculis suscipit dui. 53 = 125. Water is H2O. Nam sit amet sem. Aliquam libero nisi, imperdiet at, tincidunt nec, gravida vehicula, nisl. The New York Times (That’s a citation). Underline.Maecenas ornare tortor. Donec sed tellus eget sapien fringilla nonummy. Mauris a ante. Suspendisse quam sem, consequat at, commodo vitae, feugiat in, nunc. Morbi imperdiet augue quis tellus.&lt;/p&gt;

&lt;p&gt;HTML and CSS are our tools. Mauris a ante. Suspendisse quam sem, consequat at, commodo vitae, feugiat in, nunc. Morbi imperdiet augue quis tellus. Praesent mattis, massa quis luctus fermentum, turpis mi volutpat justo, eu volutpat enim diam eget metus.&lt;/p&gt;

&lt;h3 id=&quot;blockquotes&quot;&gt;Blockquotes&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Lorem ipsum dolor sit amet, test link adipiscing elit. Nullam dignissim convallis est. Quisque aliquam.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;list-types&quot;&gt;List Types&lt;/h2&gt;

&lt;h3 id=&quot;ordered-lists&quot;&gt;Ordered Lists&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Item one
    &lt;ol&gt;
      &lt;li&gt;sub item one&lt;/li&gt;
      &lt;li&gt;sub item two&lt;/li&gt;
      &lt;li&gt;sub item three&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Item two&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;unordered-lists&quot;&gt;Unordered Lists&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Item one&lt;/li&gt;
  &lt;li&gt;Item two&lt;/li&gt;
  &lt;li&gt;Item three&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tables&quot;&gt;Tables&lt;/h2&gt;

&lt;table rules=&quot;groups&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Header1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Header2&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Header3&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cell1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;cell2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;cell3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cell4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;cell5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;cell6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cell1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;cell2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;cell3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cell4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;cell5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;cell6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  &lt;tfoot&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Foot1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Foot2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Foot3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tfoot&gt;
&lt;/table&gt;

&lt;h2 id=&quot;code-snippets&quot;&gt;Code Snippets&lt;/h2&gt;

&lt;div class=&quot;language-css highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nf&quot;&gt;#container&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;margin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;-240px&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;buttons&quot;&gt;Buttons&lt;/h2&gt;

&lt;p&gt;Make any link standout more when applying the &lt;code class=&quot;highlighter-rouge&quot;&gt;.btn&lt;/code&gt; class.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;a&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;btn btn--success&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;Success Button&lt;span class=&quot;nt&quot;&gt;&amp;lt;/a&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div&gt;&lt;a href=&quot;#&quot; class=&quot;btn&quot;&gt;Primary Button&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--success&quot;&gt;Success Button&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--warning&quot;&gt;Warning Button&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--danger&quot;&gt;Danger Button&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--info&quot;&gt;Info Button&lt;/a&gt;&lt;/div&gt;

&lt;h2 id=&quot;notices&quot;&gt;Notices&lt;/h2&gt;

&lt;p class=&quot;notice&quot;&gt;&lt;strong&gt;Watch out!&lt;/strong&gt; You can also add notices by appending &lt;code class=&quot;highlighter-rouge&quot;&gt;{: .notice}&lt;/code&gt; to a paragraph.&lt;/p&gt;</content><author><name>Zhang Keke</name><email>apostpascal@gmail.com</email></author><category term="Layout" /><category term="table of contents" /><summary type="html">Enable table of contents on post or page by adding {% include toc %} where you’d like it to appear.</summary></entry><entry><title type="html">Reading Weekly</title><link href="http://localhost:4000/reading%20list/readlist/" rel="alternate" type="text/html" title="Reading Weekly" /><published>2018-04-25T00:00:00+08:00</published><updated>2018-04-25T00:00:00+08:00</updated><id>http://localhost:4000/reading%20list/readlist</id><content type="html" xml:base="http://localhost:4000/reading%20list/readlist/">&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Date&lt;/th&gt;
      &lt;th&gt;Title&lt;/th&gt;
      &lt;th&gt;Author&lt;/th&gt;
      &lt;th&gt;Recap&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;2018-04-26&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://web.mit.edu/tslvr/www/lessons_two_years.html&quot;&gt;Lessons from My First Two Years of AI Research&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Tom Silver&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Title: &lt;a href=&quot;http://web.mit.edu/tslvr/www/lessons_two_years.html&quot;&gt;Lessons from My First Two Years of AI Research&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Date: 2018-04-26&lt;/p&gt;

&lt;p&gt;Author: Tom Silver&lt;/p&gt;

&lt;p&gt;Recap:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ds&lt;/li&gt;
  &lt;li&gt;ds&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;</content><author><name>Zhang Keke</name></author><category term="weekly" /><summary type="html">Date Title Author Recap 2018-04-26 Lessons from My First Two Years of AI Research Tom Silver No</summary></entry><entry><title type="html">Products</title><link href="http://localhost:4000/math/products/" rel="alternate" type="text/html" title="Products" /><published>2018-04-16T00:00:00+08:00</published><updated>2018-04-16T00:00:00+08:00</updated><id>http://localhost:4000/math/products</id><content type="html" xml:base="http://localhost:4000/math/products/">&lt;h3 id=&quot;dot-product点积&quot;&gt;Dot Product(点积)&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vec{a}=[a_1,a_2,a_3]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vec{b}=[b_1, b_2, b_3]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\vec{a} \cdot \vec{b} &amp;=a_1 \cdot b_1 +a_2 \cdot b_2 + a_3 \cdot b_3\\
&amp;= |\vec{a}|  |\vec{b}|  cos(\vec{a},\vec{b})\\
\end{align*} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;vector-product叉乘向量积外积叉积矢积&quot;&gt;Vector Product（叉乘，向量积，外积、叉积，矢积）&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;|\vec{a} \times \vec{b}| = |\vec{a}|  |\vec{b}|  sin(\vec{a},\vec{b})&lt;/script&gt;

&lt;blockquote&gt;
  &lt;p&gt;其方向与$\vec{a} ,\vec{b}$的平面垂直，且遵循右手定则&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;poin-wise-逐点&quot;&gt;Poin-wise (逐点)&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vec{a} \cdot \vec{b} =(a_1 \cdot b_1 ,a_2 \cdot b_2 , a_3 \cdot b_3)&lt;/script&gt;</content><author><name>Zhang Keke</name></author><category term="math" /><category term="linear algebra" /><summary type="html">Dot Product(点积)</summary></entry><entry><title type="html">Distributed Tensorflow</title><link href="http://localhost:4000/machine%20learning/deep%20learning/distributed-tensorflow/" rel="alternate" type="text/html" title="Distributed Tensorflow" /><published>2018-04-02T00:00:00+08:00</published><updated>2018-04-02T00:00:00+08:00</updated><id>http://localhost:4000/machine%20learning/deep%20learning/distributed-tensorflow</id><content type="html" xml:base="http://localhost:4000/machine%20learning/deep%20learning/distributed-tensorflow/">&lt;h3 id=&quot;terminology&quot;&gt;Terminology&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Cluster: A cluster is composed of one or more Tensorflow servers, called tasks.&lt;/li&gt;
  &lt;li&gt;Job: a group of tasks that have a common roal. For instance, parameters server, worker server.&lt;/li&gt;
  &lt;li&gt;Task: A task corresponds to a specific TensorFlow server, and typically corresponds to a single process. A task belongs to a particular “job” and is identified by its index within that job’s list of tasks.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;div id=&quot;entry-table-of-contents&quot; class=&quot;toc-wrapper&quot;&gt;
  &lt;h2 id=&quot;toc-toggle&quot; class=&quot;no_toc&quot;&gt;
  Table of Contents &lt;i class=&quot;toc-toggle-icon fas fa-chevron-down&quot;&gt;&lt;/i&gt;
&lt;/h2&gt;
&lt;ol id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#terminology&quot; id=&quot;markdown-toc-terminology&quot;&gt;Terminology&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#multiple-devices-on-a-single-machine&quot; id=&quot;markdown-toc-multiple-devices-on-a-single-machine&quot;&gt;Multiple Devices on a Single Machine&lt;/a&gt;    &lt;ol&gt;
      &lt;li&gt;&lt;a href=&quot;#dependencies&quot; id=&quot;markdown-toc-dependencies&quot;&gt;Dependencies:&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#managing-gpu-ram&quot; id=&quot;markdown-toc-managing-gpu-ram&quot;&gt;Managing GPU RAM&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#placing-operations-on-devices&quot; id=&quot;markdown-toc-placing-operations-on-devices&quot;&gt;Placing operations on Devices&lt;/a&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#multiple-devices-across-multiple-servers&quot; id=&quot;markdown-toc-multiple-devices-across-multiple-servers&quot;&gt;Multiple Devices Across Multiple Servers&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#advantages&quot; id=&quot;markdown-toc-advantages&quot;&gt;Advantages:&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#parallelizing-neural-network-on-a--tensorflow-cluster&quot; id=&quot;markdown-toc-parallelizing-neural-network-on-a--tensorflow-cluster&quot;&gt;Parallelizing Neural Network on a  Tensorflow Cluster&lt;/a&gt;    &lt;ol&gt;
      &lt;li&gt;&lt;a href=&quot;#one-neural-network-per-device&quot; id=&quot;markdown-toc-one-neural-network-per-device&quot;&gt;One Neural Network per device&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#in-graph-versus-between-graph-replication-ensemble&quot; id=&quot;markdown-toc-in-graph-versus-between-graph-replication-ensemble&quot;&gt;In-Graph Versus Between-Graph Replication (ensemble)&lt;/a&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#model-parallelism&quot; id=&quot;markdown-toc-model-parallelism&quot;&gt;Model Parallelism&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-parallelism&quot; id=&quot;markdown-toc-data-parallelism&quot;&gt;Data Parallelism&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reference&quot; id=&quot;markdown-toc-reference&quot;&gt;Reference:&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;

&lt;h3 id=&quot;multiple-devices-on-a-single-machine&quot;&gt;Multiple Devices on a Single Machine&lt;/h3&gt;
&lt;h4 id=&quot;dependencies&quot;&gt;Dependencies:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;CUDA: Nvidia’s Compute Unified Device Architecture Library allows developers to call GPUs&lt;/li&gt;
  &lt;li&gt;cuDNN: CUDA deep neural network library to call CUDA&lt;/li&gt;
  &lt;li&gt;tensorflow-gpu&lt;/li&gt;
&lt;/ul&gt;

&lt;figure style=&quot;width: 400px&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;http://localhost:4000/images/resources/EF7FF3FE23EE675AA38920A81F91B7E7.png&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;CUDA, cuDNN and Tensorflow &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h4 id=&quot;managing-gpu-ram&quot;&gt;Managing GPU RAM&lt;/h4&gt;
&lt;p&gt;By default Tensorflow will grab all the RAM in all available GPUs the first time you run a graph, so if you run a second Tensorflow program, Memory error showing up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One solution is to run each process  on different GPU card.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# run script in specific GPU card&lt;/span&gt;
CUDA_VISIBLE_DEVICES &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0,1 python3 program.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;Another option is to set a threshold for Tensorflow, which limits the program can only grab a fraction of GPUs’ memory.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;config = tf.ConfigProto()
config.gpu_option.per_process_gpu_memory_fraction = 0.4
session = tf.Session(config=config)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&quot;placing-operations-on-devices&quot;&gt;Placing operations on Devices&lt;/h4&gt;

&lt;p&gt;Using the following code to place operation to a specific device, otherwise it will place to the default device.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Cautions: there is no way to pin nodes on a specific CPUs or a subset CPUS&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/cpu:0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;multiple-devices-across-multiple-servers&quot;&gt;Multiple Devices Across Multiple Servers&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Create a Clusesr&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cluser_spec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ClusterSpec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;worker&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;machine-a.example.com:2222&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#/job:worker/task:0&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;machine-b.example.com:2222&quot;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#/job:worker/task:1&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;ps&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;machine-a.example.com:2221&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#/job:ps/task:0&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;figure style=&quot;width: 400px&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;http://localhost:4000/images/resources/5246338809A70A300174F06780A8F7A6.png&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;Distributed Tensorflow &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Run a server&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster_spec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;worker&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task_index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# start first worker task&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;server.join()&lt;/code&gt; to wait servers finish&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;In distribution tensorflow, variables maintain by resource container. In other words, we can access the variable across different sessions and servers. To avoid name clash, we can wrap variables by using &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.variable_scope&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.container&lt;/code&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.container&lt;/code&gt; is easy to reset and release variables.&lt;/p&gt;
  &lt;h3 id=&quot;advantages&quot;&gt;Advantages:&lt;/h3&gt;
  &lt;ul&gt;
    &lt;li&gt;Be able to explore a much larger hyperparameter space when fine-tuning your model&lt;/li&gt;
    &lt;li&gt;Large ensembles of NN efficiently&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;parallelizing-neural-network-on-a--tensorflow-cluster&quot;&gt;Parallelizing Neural Network on a  Tensorflow Cluster&lt;/h3&gt;
&lt;h4 id=&quot;one-neural-network-per-device&quot;&gt;One Neural Network per device&lt;/h4&gt;

&lt;figure style=&quot;width: 400px&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;http://localhost:4000/images/resources/E856AD8B0ED2C7CDCDB45564C7422896.png&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt; &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;One client per neural network per device.Each device running similar neural network with different hyperparameters.This solution is perfect for hyperparameter tuning.&lt;/p&gt;

&lt;h4 id=&quot;in-graph-versus-between-graph-replication-ensemble&quot;&gt;In-Graph Versus Between-Graph Replication (ensemble)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;In-Graph: one client,one graph, one session maintains all stuff, one neural network per device.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure style=&quot;width: 400px&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;http://localhost:4000/images/resources/2DA0DD8414DA59C6A9C4DA0C4AC202BE.png&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;In-Graph &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Between-Graph: several clients maintain &lt;code class=&quot;highlighter-rouge&quot;&gt;Input&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Output&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Neural Network&lt;/code&gt;. Each Neural network is an individual graph.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure style=&quot;width: 400px&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;http://localhost:4000/images/resources/A15BD70A71FED16E09A3B9128E767E5D.png&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;Between-Graph&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;model-parallelism&quot;&gt;Model Parallelism&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Separate Neural network Horizontally or Vertically.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure style=&quot;width: 400px&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;http://localhost:4000/images/resources/69478BB7441E6A92A5E495EA467E9BC0.png&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;Model Parallelism&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&quot;data-parallelism&quot;&gt;Data Parallelism&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Each device running same neural network, but feeded different mini-batch data. For each iteration, neural network fetch parameters from &lt;code class=&quot;highlighter-rouge&quot;&gt;PS&lt;/code&gt;, then Gradients from each network aggrated to update parameters in &lt;code class=&quot;highlighter-rouge&quot;&gt;PS&lt;/code&gt;. There are two main approach, &lt;em&gt;synchronous&lt;/em&gt; and &lt;em&gt;asynchronous&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;With synchronous updates, the aggregator waits for all gradients to be available before computing the average and applying the result.The downside is faster replica have to wait slower one at every iteration. To make it more efficient, we can update parameters only if a fraction of replicas has finished.&lt;/li&gt;
  &lt;li&gt;With asynchronous updates, whenever a replica has finished computing the gradients, it immediately uses them to update the model parameters.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure style=&quot;width: 400px&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;http://localhost:4000/images/resources/858A8FB5C9CCA2CD3E954C58C610187A.png&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;Data Parallelism&lt;/figcaption&gt;

&lt;/figure&gt;
&lt;hr /&gt;
&lt;h3 id=&quot;reference&quot;&gt;Reference:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.tensorflow.org/deploy/distributed&quot;&gt;Distributed Tensorflow&lt;/a&gt;: Tensorflow official doc&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tensorflow/ecosystem&quot;&gt;Echosystem&lt;/a&gt;: tensorflow official github project, a integration of tensorflow with other open-source framework&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://g.co/kgs/dHRoaa&quot;&gt;Hands-on Machine Learning with Scikit_Learn &amp;amp; Tensorflow&lt;/a&gt;: Chapter 12, Distributing Tensorflow Across Devices and Server&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;</content><author><name>Zhang Keke</name></author><category term="Tensorflow" /><category term="Distribution" /><summary type="html">Terminology Cluster: A cluster is composed of one or more Tensorflow servers, called tasks. Job: a group of tasks that have a common roal. For instance, parameters server, worker server. Task: A task corresponds to a specific TensorFlow server, and typically corresponds to a single process. A task belongs to a particular “job” and is identified by its index within that job’s list of tasks.</summary></entry><entry><title type="html">Machine Learning Tips</title><link href="http://localhost:4000/machine%20learning/reading/recap/Machine-Learning-tips/" rel="alternate" type="text/html" title="Machine Learning Tips" /><published>2018-02-23T00:00:00+08:00</published><updated>2018-02-23T00:00:00+08:00</updated><id>http://localhost:4000/machine%20learning/reading/recap/Machine-Learning-tips</id><content type="html" xml:base="http://localhost:4000/machine%20learning/reading/recap/Machine-Learning-tips/">&lt;p&gt;Recap of Martin Zinkevich’s blog 
&lt;a href=&quot;http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf&quot;&gt;Best Practices for ML Engineering&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;before-machine-learning&quot;&gt;Before Machine Learning&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Do machine learning like the great engineer you are, not like the expert you aren't.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;Machine learning is all of Engineering.
ML is limited, but engineering is not. 
Engineering’s destiny is to quantify problems then solve it. In this case, the first target is how to quantify problems — Design metrics.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;1: Don’t be afraid to launch a product without machine learning.&lt;/li&gt;
  &lt;li&gt;2: Make metrics design and implementation a priority.&lt;/li&gt;
  &lt;li&gt;3: Choose machine learning over a complex heuristic.
    &lt;h3 id=&quot;ml-phase-i-your-first-pipeline&quot;&gt;ML Phase I: Your First Pipeline&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;4: Keep the first model simple and get the infrastructure right.&lt;/li&gt;
  &lt;li&gt;5: Test the infrastructure independently from the machine learning.&lt;/li&gt;
  &lt;li&gt;6: Be careful about dropped data when copying pipelines.&lt;/li&gt;
  &lt;li&gt;7: Turn heuristics into features, or handle them externally.
    &lt;blockquote&gt;
      &lt;p&gt;stand on giant’s shoulders&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;8: Know the freshness requirements of your system.
    &lt;blockquote&gt;
      &lt;p&gt;How fast you will lost revenue with time goes by.How open you should update your model&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;9: Detect problems before exporting models.&lt;/li&gt;
  &lt;li&gt;10: Watch for silent failures.
    &lt;blockquote&gt;
      &lt;p&gt;Track statistics of Data, before preprocessing and feeds&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;11: Give feature sets owners and documentation.
    &lt;h3 id=&quot;your-first-objective&quot;&gt;Your First Objective&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;12: Don’t overthink which objective you choose to directly optimize.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;13: Choose a simple, observable and attributable metric for your first objective.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;14: Starting with an interpretable model makes debugging easier.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;15: Separate Spam Filtering and Quality Ranking in a Policy Layer.
    &lt;h3 id=&quot;ml-phase-ii-feature-engineering&quot;&gt;ML Phase II: Feature Engineering&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;16: Plan to launch and iterate.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;17: Start with directly observed and reported features as opposed to learned features.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;18: Explore with features of content that generalize across contexts.&lt;/li&gt;
  &lt;li&gt;19: Use very specific features when you can.&lt;/li&gt;
  &lt;li&gt;20: Combine and modify existing features to create new features in human understandable ways.&lt;/li&gt;
  &lt;li&gt;21: The number of feature weights you can learn in a linear model is roughly proportional to the amount of data you have.&lt;/li&gt;
  &lt;li&gt;22: Clean up features you are no longer using.
    &lt;blockquote&gt;
      &lt;p&gt;Unused features create technical debt&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;human-analysis-of-the-system&quot;&gt;Human Analysis of the System&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;23: You are not a typical end user.&lt;/li&gt;
  &lt;li&gt;24: Measure the delta between models.&lt;/li&gt;
  &lt;li&gt;25: When choosing models, utilitarian performance trumps predictive power.&lt;/li&gt;
  &lt;li&gt;26: Look for patterns in the measured errors, and create new features.&lt;/li&gt;
  &lt;li&gt;27: Try to quantify observed undesirable behavior.
    &lt;blockquote&gt;
      &lt;p&gt;Quantify bad part and improve it. Again, Metric is the first important thing
At this point, they should do whatever it takes to turn their gripes into solid numbers.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;28: Be aware that identical short term behavior does not imply identical long term behavior.
    &lt;h3 id=&quot;training-serving-skew&quot;&gt;Training-Serving Skew&lt;/h3&gt;
    &lt;blockquote&gt;
      &lt;p&gt;The best solution is to explicitly monitor it so that system and  data changes don’t introduce skew unnoticed.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;29: The best way to make sure that you train like you serve is to save the set of features used at serving time, and then pipe those features to a log to use them at training time.&lt;/li&gt;
  &lt;li&gt;30: Importance weight sampled data, don’t arbitrarily drop it!&lt;/li&gt;
  &lt;li&gt;31: Beware that if you join data from a table at training and serving time, the data in the table may change.&lt;/li&gt;
  &lt;li&gt;32: Reuse code between your training pipeline and your serving pipeline whenever possible.&lt;/li&gt;
  &lt;li&gt;33: If you produce a model based on the data until January 5th, test the model on the data from January 6th and after.
    &lt;blockquote&gt;
      &lt;p&gt;use next-day data&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;34: In binary classification for filtering (such as spam detection or determining interesting emails), make small short term sacrifices in performance for very clean data.&lt;/li&gt;
  &lt;li&gt;35: Beware of the inherent skew in ranking problems.&lt;/li&gt;
  &lt;li&gt;36: Avoid feedback loops with positional features.&lt;/li&gt;
  &lt;li&gt;37: Measure Training/Serving Skew.
    &lt;blockquote&gt;
      &lt;p&gt;Training data, validation data, test data(next data), live data.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ml-phase-iii-slowed-growth-optimization-refinement-and-complex-models&quot;&gt;ML Phase III: Slowed Growth, Optimization Refinement, and Complex Models&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;38: Don’t waste time on new features if unaligned objectives have become the issue.&lt;/li&gt;
  &lt;li&gt;39: Launch decisions will depend upon more than one metric.&lt;/li&gt;
  &lt;li&gt;40: Keep ensembles simple.&lt;/li&gt;
  &lt;li&gt;41: When performance plateaus, look for qualitatively new sources of information to add rather than refining existing signals.&lt;/li&gt;
  &lt;li&gt;42: Don’t expect diversity, personalization, or relevance to be as correlated with popularity as you think they are.&lt;/li&gt;
  &lt;li&gt;43: Your friends tend to be the same across different products. Your interests tend not to be.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Zhang Keke</name></author><category term="Tips" /><summary type="html">Recap of Martin Zinkevich’s blog Best Practices for ML Engineering</summary></entry><entry><title type="html">智能时代</title><link href="http://localhost:4000/extraction/reading/%E6%99%BA%E8%83%BD%E6%97%B6%E4%BB%A3/" rel="alternate" type="text/html" title="智能时代" /><published>2017-12-02T00:00:00+08:00</published><updated>2017-12-02T00:00:00+08:00</updated><id>http://localhost:4000/extraction/reading/%E6%99%BA%E8%83%BD%E6%97%B6%E4%BB%A3</id><content type="html" xml:base="http://localhost:4000/extraction/reading/%E6%99%BA%E8%83%BD%E6%97%B6%E4%BB%A3/">&lt;h1 id=&quot;智能时代&quot;&gt;智能时代&lt;/h1&gt;

&lt;hr /&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;出版时间:2017
作者:吴军
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;正如书名一样，书里描绘里一个智能的时代。或者说是一个数据驱动的时代。科技的进步来源于人类对自然或或者说是事物的认知。也可以换一种说法，是来源于数据。人类的进步就是数据的积累。人们不断的从数据里总结，学习。从而才能产生知识—-一种对数据加工而得到的结论。人类的早期对数据的收集都比较慢，即没有工具，也没有处理的方法。这也就造成了人类的认知不足。随着时间的发展，数据量渐渐增大，人类可以从数据中提炼，挖掘出有效的信息，根据先验知识或者是由数据驱动。这就是我的工作，有效的挖掘数据的潜在价值，利用数据提取信息，进而用这些信息做一些事。所谓智能，不过是把数据中的信息挖掘出智能。比方说图像分类，人脸识别，声音识别。都是来源于数据，并且对数据加工，提取数据的共性，并且放大那些决定性的差异，然后才进行分类。另外一方面也十分重要，那就是对数据的收集。或者说是制造数据。这是对数据智能的前提。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;总的来说，就是用智能改进传统行业，分两步&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;利用新的硬件收集传统行业的数据，量化传统行业的各个关键部分，对数据收集整理&lt;/li&gt;
  &lt;li&gt;通过数据对自身的反馈做出改变，并且用数据引领企业。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;难点&quot;&gt;难点：&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;传统行业，比如养殖业，农业，从事这些行业的人大多文化水平不高，对他们的数据难以收集&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Zhang Keke</name></author><category term="AI" /><summary type="html">智能时代</summary></entry><entry><title type="html">PCA</title><link href="http://localhost:4000/machine%20learning/pca/" rel="alternate" type="text/html" title="PCA" /><published>2017-09-11T20:08:50+08:00</published><updated>2017-09-11T20:08:50+08:00</updated><id>http://localhost:4000/machine%20learning/pca</id><content type="html" xml:base="http://localhost:4000/machine%20learning/pca/">&lt;div id=&quot;entry-table-of-contents&quot; class=&quot;toc-wrapper&quot;&gt;
  &lt;h2 id=&quot;toc-toggle&quot; class=&quot;no_toc&quot;&gt;
  Table of Contents &lt;i class=&quot;toc-toggle-icon fas fa-chevron-down&quot;&gt;&lt;/i&gt;
&lt;/h2&gt;
&lt;ol id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#方差&quot; id=&quot;markdown-toc-方差&quot;&gt;方差&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#协方差&quot; id=&quot;markdown-toc-协方差&quot;&gt;协方差&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#协方差矩阵&quot; id=&quot;markdown-toc-协方差矩阵&quot;&gt;协方差矩阵&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#算法及实例&quot; id=&quot;markdown-toc-算法及实例&quot;&gt;算法及实例&lt;/a&gt;    &lt;ol&gt;
      &lt;li&gt;&lt;a href=&quot;#pca算法&quot; id=&quot;markdown-toc-pca算法&quot;&gt;PCA算法&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#实例&quot; id=&quot;markdown-toc-实例&quot;&gt;实例&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#进一步讨论&quot; id=&quot;markdown-toc-进一步讨论&quot;&gt;进一步讨论&lt;/a&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.codinglabs.org/articles/pca-tutorial.html&quot;&gt;Blog Source:&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;方差&quot;&gt;方差&lt;/h2&gt;
&lt;p&gt;上文说到，我们希望投影后投影值尽可能分散，而这种分散程度，可以用数学上的方差来表述。此处，一个字段的方差可以看做是每个元素与字段均值的差的平方和的均值，即：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(a)=\frac{1}{m}\sum_{i=1}^m{(a_i-\mu)^2}&lt;/script&gt;

&lt;p&gt;由于上面我们已经将每个字段的均值都化为0了，因此方差可以直接用每个元素的平方和除以元素个数表示：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(a)=\frac{1}{m}\sum_{i=1}^m{a_i^2}&lt;/script&gt;

&lt;p&gt;于是上面的问题被形式化表述为：寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，方差值最大。&lt;/p&gt;
&lt;h2 id=&quot;协方差&quot;&gt;协方差&lt;/h2&gt;
&lt;p&gt;对于上面二维降成一维的问题来说，找到那个使得方差最大的方向就可以了。不过对于更高维，还有一个问题需要解决。考虑三维降到二维问题。与之前相同，首先我们希望找到一个方向使得投影后方差最大，这样就完成了第一个方向的选择，继而我们选择第二个投影方向。&lt;/p&gt;

&lt;p&gt;如果我们还是单纯只选择方差最大的方向，很明显，这个方向与第一个方向应该是“几乎重合在一起”，显然这样的维度是没有用的，因此，应该有其他约束条件。从直观上说，让两个字段尽可能表示更多的原始信息，我们是不希望它们之间存在（线性）相关性的，因为相关性意味着两个字段不是完全独立，必然存在重复表示的信息。&lt;/p&gt;

&lt;p&gt;数学上可以用两个字段的协方差表示其相关性，由于已经让每个字段均值为0，则：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cov(a,b)=\frac{1}{m}\sum_{i=1}^m{a_ib_i}&lt;/script&gt;

&lt;p&gt;可以看到，在字段均值为0的情况下，两个字段的协方差简洁的表示为其内积除以元素数m。&lt;/p&gt;

&lt;p&gt;当协方差为0时，表示两个字段完全独立。为了让协方差为0，我们选择第二个基时只能在与第一个基正交的方向上选择。因此最终选择的两个方向一定是正交的。&lt;/p&gt;

&lt;p&gt;至此，我们得到了降维问题的优化目标：将一组N维向量降为K维（K大于0，小于N），其目标是选择K个单位（模为1）正交基，使得原始数据变换到这组基上后，各字段两两间协方差为0，而字段的方差则尽可能大（在正交的约束下，取最大的K个方差）。&lt;/p&gt;

&lt;h2 id=&quot;协方差矩阵&quot;&gt;协方差矩阵&lt;/h2&gt;
&lt;p&gt;上面我们导出了优化目标，但是这个目标似乎不能直接作为操作指南（或者说算法），因为它只说要什么，但根本没有说怎么做。所以我们要继续在数学上研究计算方案。&lt;/p&gt;

&lt;p&gt;我们看到，最终要达到的目的与字段内方差及字段间协方差有密切关系。因此我们希望能将两者统一表示，仔细观察发现，两者均可以表示为内积的形式，而内积又与矩阵相乘密切相关。于是我们来了灵感：
假设我们只有a和b两个字段，那么我们将它们按行组成矩阵X：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
X= \begin{pmatrix} a_1 &amp; a_2 &amp; \cdots &amp; a_m \\ b_1 &amp; b_2 &amp; \cdots &amp; b_m \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;然后我们用X乘以X的转置，并乘上系数$1/m$：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\frac{1}{m}XX^\mathsf{T}=\begin{pmatrix} \frac{1}{m}\sum_{i=1}^m{a_i^2} &amp; \frac{1}{m}\sum_{i=1}^m{a_ib_i} \\ \frac{1}{m}\sum_{i=1}^m{a_ib_i} &amp; \frac{1}{m}\sum_{i=1}^m{b_i^2} \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;奇迹出现了！这个矩阵对角线上的两个元素分别是两个字段的方差，而其它元素是a和b的协方差。两者被统一到了一个矩阵的。&lt;/p&gt;

&lt;p&gt;根据矩阵相乘的运算法则，这个结论很容易被推广到一般情况：&lt;/p&gt;

&lt;p&gt;设我们有m个n维数据记录，将其按列排成n乘m的矩阵X，设&lt;script type=&quot;math/tex&quot;&gt;C=\frac{1}{m}XX^\mathsf{T}&lt;/script&gt;则C是一个对称矩阵，其对角线分别个各个字段的方差，而第i行j列和j行i列元素相同，表示i和j两个字段的协方差。&lt;/p&gt;

&lt;p&gt;##协方差矩阵对角化
根据上述推导，我们发现要达到优化目前，等价于将协方差矩阵对角化：即除对角线外的其它元素化为0，并且在对角线上将元素按大小从上到下排列，这样我们就达到了优化目的。这样说可能还不是很明晰，我们进一步看下原矩阵与基变换后矩阵协方差矩阵的关系：&lt;/p&gt;

&lt;p&gt;设原始数据矩阵X对应的协方差矩阵为C，而P是一组基按行组成的矩阵，设Y=PX，则Y为X对P做基变换后的数据。设Y的协方差矩阵为D，我们推导一下D与C的关系：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{l l l} D &amp; = &amp; \frac{1}{m}YY^\mathsf{T} \\ &amp; = &amp; \frac{1}{m}(PX)(PX)^\mathsf{T} \\ &amp; = &amp; \frac{1}{m}PXX^\mathsf{T}P^\mathsf{T} \\ &amp; = &amp; P(\frac{1}{m}XX^\mathsf{T})P^\mathsf{T} \\ &amp; = &amp; PCP^\mathsf{T} \end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;现在事情很明白了！我们要找的P不是别的，而是能让原始协方差矩阵对角化的P。换句话说，优化目标变成了寻找一个矩阵P，满足&lt;script type=&quot;math/tex&quot;&gt;PCP^\mathsf{T}&lt;/script&gt;是一个对角矩阵，并且对角元素按从大到小依次排列，那么P的前K行就是要寻找的基，用P的前K行组成的矩阵乘以X就使得X从N维降到了K维并满足上述优化条件。&lt;/p&gt;

&lt;p&gt;至此，我们离“发明”PCA还有仅一步之遥！&lt;/p&gt;

&lt;p&gt;现在所有焦点都聚焦在了协方差矩阵对角化问题上，有时，我们真应该感谢数学家的先行，因为矩阵对角化在线性代数领域已经属于被玩烂了的东西，所以这在数学上根本不是问题。&lt;/p&gt;

&lt;p&gt;由上文知道，协方差矩阵C是一个是对称矩阵，在线性代数上，实对称矩阵有一系列非常好的性质：&lt;/p&gt;

&lt;p&gt;1）实对称矩阵不同特征值对应的特征向量必然正交。&lt;/p&gt;

&lt;p&gt;2）设特征向量&lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;重数为r，则必然存在r个线性无关的特征向量对应于\lambda，因此可以将这r个特征向量单位正交化。&lt;/p&gt;

&lt;p&gt;由上面两条可知，一个n行n列的实对称矩阵一定可以找到n个单位正交特征向量，设这n个特征向量为&lt;script type=&quot;math/tex&quot;&gt;e_1,e_2,\cdots,e_n&lt;/script&gt;，我们将其按列组成矩阵：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
E=\begin{pmatrix} e_1 &amp; e_2 &amp; \cdots &amp; e_n \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;则对协方差矩阵C有如下结论：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
E^\mathsf{T}CE=\Lambda=\begin{pmatrix} \lambda_1 &amp; &amp; &amp; \\ &amp; \lambda_2 &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; \lambda_n \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;其中&lt;script type=&quot;math/tex&quot;&gt;\Lambda&lt;/script&gt;为对角矩阵，其对角元素为各特征向量对应的特征值（可能有重复）。&lt;/p&gt;

&lt;p&gt;以上结论不再给出严格的数学证明，对证明感兴趣的朋友可以参考线性代数书籍关于“实对称矩阵对角化”的内容。&lt;/p&gt;

&lt;p&gt;到这里，我们发现我们已经找到了需要的矩阵P：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P=E^\mathsf{T}&lt;/script&gt;

&lt;p&gt;P是协方差矩阵的特征向量单位化后按行排列出的矩阵，其中每一行都是C的一个特征向量。如果设P按照&lt;script type=&quot;math/tex&quot;&gt;\Lambda&lt;/script&gt;中特征值的从大到小，将特征向量从上到下排列，则用P的前K行组成的矩阵乘以原始数据矩阵X，就得到了我们需要的降维后的数据矩阵Y。&lt;/p&gt;

&lt;p&gt;至此我们完成了整个PCA的数学原理讨论。在下面的一节，我们将给出PCA的一个实例。&lt;/p&gt;

&lt;h1 id=&quot;算法及实例&quot;&gt;算法及实例&lt;/h1&gt;
&lt;p&gt;为了巩固上面的理论，我们在这一节给出一个具体的PCA实例。&lt;/p&gt;

&lt;h2 id=&quot;pca算法&quot;&gt;PCA算法&lt;/h2&gt;
&lt;p&gt;总结一下PCA的算法步骤：&lt;/p&gt;

&lt;p&gt;设有m条n维数据。&lt;/p&gt;

&lt;p&gt;1）将原始数据按列组成n行m列矩阵X&lt;/p&gt;

&lt;p&gt;2）将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值&lt;/p&gt;

&lt;p&gt;3）求出协方差矩阵&lt;script type=&quot;math/tex&quot;&gt;C=\frac{1}{m}XX^\mathsf{T}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;4）求出协方差矩阵的特征值及对应的特征向量&lt;/p&gt;

&lt;p&gt;5）将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P&lt;/p&gt;

&lt;p&gt;6）Y=PX即为降维到k维后的数据&lt;/p&gt;

&lt;h2 id=&quot;实例&quot;&gt;实例&lt;/h2&gt;
&lt;p&gt;这里以上文提到的&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{pmatrix} -1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\ -2 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;为例，我们用PCA方法将这组二维数据其降到一维。&lt;/p&gt;

&lt;p&gt;因为这个矩阵的每行已经是零均值，这里我们直接求协方差矩阵：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
C=\frac{1}{5}\begin{pmatrix} -1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\ -2 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \end{pmatrix}\begin{pmatrix} -1 &amp; -2 \\ -1 &amp; 0 \\ 0 &amp; 0 \\ 2 &amp; 1 \\ 0 &amp; 1 \end{pmatrix}=\begin{pmatrix} \frac{6}{5} &amp; \frac{4}{5} \\ \frac{4}{5} &amp; \frac{6}{5} \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;然后求其特征值和特征向量，具体求解方法不再详述，可以参考相关资料。求解后特征值为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lambda_1=2,\lambda_2=2/5&lt;/script&gt;

&lt;p&gt;其对应的特征向量分别是：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;c_1\begin{pmatrix} 1 \\ 1 \end{pmatrix},c_2\begin{pmatrix} -1 \\ 1 \end{pmatrix}&lt;/script&gt;

&lt;p&gt;其中对应的特征向量分别是一个通解，&lt;script type=&quot;math/tex&quot;&gt;c_1和c_2&lt;/script&gt;可取任意实数。那么标准化后的特征向量为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{pmatrix} 1/\sqrt{2} \\ 1/\sqrt{2} \end{pmatrix},\begin{pmatrix} -1/\sqrt{2} \\ 1/\sqrt{2} \end{pmatrix}&lt;/script&gt;

&lt;p&gt;因此我们的矩阵P是：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
P=\begin{pmatrix} 1/\sqrt{2} &amp; 1/\sqrt{2} \\ -1/\sqrt{2} &amp; 1/\sqrt{2} \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;可以验证协方差矩阵C的对角化：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
PCP^\mathsf{T}=\begin{pmatrix} 1/\sqrt{2} &amp; 1/\sqrt{2} \\ -1/\sqrt{2} &amp; 1/\sqrt{2} \end{pmatrix}\begin{pmatrix} 6/5 &amp; 4/5 \\ 4/5 &amp; 6/5 \end{pmatrix}\begin{pmatrix} 1/\sqrt{2} &amp; -1/\sqrt{2} \\ 1/\sqrt{2} &amp; 1/\sqrt{2} \end{pmatrix}=\begin{pmatrix} 2 &amp; 0 \\ 0 &amp; 2/5 \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;最后我们用P的第一行乘以数据矩阵，就得到了降维后的表示：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
Y=\begin{pmatrix} 1/\sqrt{2} &amp; 1/\sqrt{2} \end{pmatrix}\begin{pmatrix} -1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\ -2 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \end{pmatrix}=\begin{pmatrix} -3/\sqrt{2} &amp; -1/\sqrt{2} &amp; 0 &amp; 3/\sqrt{2} &amp; -1/\sqrt{2} \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;降维投影结果如下图:&lt;/p&gt;

&lt;figure style=&quot;width: 250px&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;http://localhost:4000/images/pca.png&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;PCA image.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;进一步讨论&quot;&gt;进一步讨论&lt;/h2&gt;
&lt;p&gt;根据上面对PCA的数学原理的解释，我们可以了解到一些PCA的能力和限制。PCA本质上是将方差最大的方向作为主要特征，并且在各个正交方向上将数据“离相关”，也就是让它们在不同正交方向上没有相关性。&lt;/p&gt;

&lt;p&gt;因此，PCA也存在一些限制，例如它可以很好的解除线性相关，但是对于高阶相关性就没有办法了，对于存在高阶相关性的数据，可以考虑Kernel PCA，通过Kernel函数将非线性相关转为线性相关，关于这点就不展开讨论了。另外，PCA假设数据各主特征是分布在正交方向上，如果在非正交方向上存在几个方差较大的方向，PCA的效果就大打折扣了。&lt;/p&gt;

&lt;p&gt;最后需要说明的是，PCA是一种无参数技术，也就是说面对同样的数据，如果不考虑清洗，谁来做结果都一样，没有主观参数的介入，所以PCA便于通用实现，但是本身无法个性化的优化。&lt;/p&gt;

&lt;p&gt;希望这篇文章能帮助朋友们了解PCA的数学理论基础和实现原理，借此了解PCA的适用场景和限制，从而更好的使用这个算法。&lt;/p&gt;</content><author><name>Zhang Keke</name></author><category term="math" /><category term="PCA" /><category term="dimension reduction" /><summary type="html">Table of Contents</summary></entry><entry><title type="html">Maximum Likelihood Estimation</title><link href="http://localhost:4000/math/mle/" rel="alternate" type="text/html" title="Maximum Likelihood Estimation" /><published>2017-02-01T00:00:00+08:00</published><updated>2017-02-01T00:00:00+08:00</updated><id>http://localhost:4000/math/mle</id><content type="html" xml:base="http://localhost:4000/math/mle/">&lt;div id=&quot;entry-table-of-contents&quot; class=&quot;toc-wrapper&quot;&gt;
  &lt;h2 id=&quot;toc-toggle&quot; class=&quot;no_toc&quot;&gt;
  Table of Contents &lt;i class=&quot;toc-toggle-icon fas fa-chevron-down&quot;&gt;&lt;/i&gt;
&lt;/h2&gt;
&lt;ol id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#bayesian-rule&quot; id=&quot;markdown-toc-bayesian-rule&quot;&gt;Bayesian Rule:&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#maximum-likelihood-estimation-mle&quot; id=&quot;markdown-toc-maximum-likelihood-estimation-mle&quot;&gt;Maximum Likelihood Estimation (MLE)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;

&lt;h3 id=&quot;bayesian-rule&quot;&gt;Bayesian Rule:&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\theta|D)=\frac{P(D|\theta)P(\theta)}{P(D)}&lt;/script&gt;

&lt;p&gt;$P(D \mid \theta) \Rightarrow$ Likelihood&lt;/p&gt;

&lt;p&gt;$P(\theta) \Rightarrow$ prior&lt;/p&gt;

&lt;p&gt;$P(\theta \mid D) \Rightarrow$ posterior&lt;/p&gt;

&lt;p&gt;$P(D) \Rightarrow$ marginal likelihood&lt;/p&gt;

&lt;h3 id=&quot;maximum-likelihood-estimation-mle&quot;&gt;Maximum Likelihood Estimation (MLE)&lt;/h3&gt;
&lt;p&gt;AKA:最大似然估计，likelihood AKA: 似然函数&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(D|\theta)=\prod\limits_{x_i \in D} p(x_i|\theta)&lt;/script&gt;

&lt;p&gt;Apply log operation to avoid underflow&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;logP(D|\theta)=\sum\limits_{x_i \in D}log(p(x_i|\theta))&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta=arg\space  MAX\space  logP(D|\theta)&lt;/script&gt;

&lt;p&gt;For instance,if &lt;script type=&quot;math/tex&quot;&gt;P(x \mid \theta) \sim N(u,\sigma^2)&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{u}=\frac{1}{|D|}\sum\limits_{x_i \in D} x_i&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\sigma}^2=\frac{1}{|D|}\sum\limits_{x_i \in D}(x_i-\hat{u})(x_i-\hat{u})^T&lt;/script&gt;</content><author><name>Zhang Keke</name></author><category term="MLE" /><summary type="html">Table of Contents</summary></entry></feed>